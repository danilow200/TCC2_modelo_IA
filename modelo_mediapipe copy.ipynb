{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializando o MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5)\n",
    "\n",
    "# Pasta com os vídeos\n",
    "pasta_videos = './pasta2 - Copia'\n",
    "\n",
    "# Listas para armazenar os dados e os rótulos\n",
    "dados_uma_mao = []\n",
    "rotulos_uma_mao = []\n",
    "dados_duas_maos = []\n",
    "rotulos_duas_maos = []\n",
    "\n",
    "# Dicionário para armazenar as coordenadas por palavra\n",
    "coordenadas_por_palavra = {'uma': {}, 'duas': {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danil\\Documents\\GitHub\\TCC2_modelo_IA\\myenv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo (uma mão): 0.00%\n",
      "Acurácia do modelo (duas mãos): 0.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['modelo_duas_maos.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for categoria in ['uma', 'duas']:\n",
    "    caminho_categoria = os.path.join(pasta_videos, categoria)\n",
    "    for subpasta in os.listdir(caminho_categoria):\n",
    "        caminho_subpasta = os.path.join(caminho_categoria, subpasta)\n",
    "        for video in os.listdir(caminho_subpasta):\n",
    "            # Lendo o vídeo\n",
    "            cap = cv2.VideoCapture(os.path.join(caminho_subpasta, video))\n",
    "            \n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                \n",
    "                # Convertendo a cor da imagem\n",
    "                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                # Processando a imagem\n",
    "                result = hands.process(image)\n",
    "                \n",
    "                if result.multi_hand_landmarks and result.multi_handedness:\n",
    "                    if categoria == 'uma':\n",
    "                        # Para palavras de uma mão, consideramos apenas a mão direita\n",
    "                        for hand_landmarks, handedness in zip(result.multi_hand_landmarks, result.multi_handedness):\n",
    "                            hand_label = handedness.classification[0].label.lower()\n",
    "                            if hand_label == 'right':\n",
    "                                # Extraindo as coordenadas\n",
    "                                coords = list(np.array([[landmark.x, landmark.y, landmark.z] for landmark in hand_landmarks.landmark]).flatten())\n",
    "                                \n",
    "                                # Adicionando as coordenadas à lista de dados\n",
    "                                dados_uma_mao.append(coords)\n",
    "                                # Adicionando o rótulo à lista de rótulos\n",
    "                                rotulos_uma_mao.append(subpasta)\n",
    "                                \n",
    "                                # Armazenando as coordenadas por palavra\n",
    "                                if subpasta not in coordenadas_por_palavra['uma']:\n",
    "                                    coordenadas_por_palavra['uma'][subpasta] = []\n",
    "                                coordenadas_por_palavra['uma'][subpasta].append(tuple(coords))\n",
    "                    else:\n",
    "                        # Para palavras de duas mãos, consideramos as duas mãos\n",
    "                        for hand_landmarks, handedness in zip(result.multi_hand_landmarks, result.multi_handedness):\n",
    "                            # Identificar se a mão é direita ou esquerda\n",
    "                            hand_label = handedness.classification[0].label.lower()\n",
    "                            if hand_label == 'right':\n",
    "                                hand_label = 'direita'\n",
    "                            else:\n",
    "                                hand_label = 'esquerda'\n",
    "                            \n",
    "                            # Extraindo as coordenadas\n",
    "                            coords = list(np.array([[landmark.x, landmark.y, landmark.z] for landmark in hand_landmarks.landmark]).flatten())\n",
    "                            \n",
    "                            # Adicionando as coordenadas à lista de dados\n",
    "                            dados_duas_maos.append(coords)\n",
    "                            # Adicionando o rótulo à lista de rótulos\n",
    "                            rotulos_duas_maos.append(subpasta)\n",
    "                            \n",
    "                            # Armazenando as coordenadas por palavra e mão\n",
    "                            if subpasta not in coordenadas_por_palavra['duas']:\n",
    "                                coordenadas_por_palavra['duas'][subpasta] = []\n",
    "                            coordenadas_por_palavra['duas'][subpasta].append(tuple(coords))\n",
    "\n",
    "# Selecionando a coordenada mais frequente por palavra\n",
    "coordenadas_selecionadas_uma = {}\n",
    "coordenadas_selecionadas_duas = {'direita': {}, 'esquerda': {}}\n",
    "\n",
    "for palavra, coords_lista in coordenadas_por_palavra['uma'].items():\n",
    "    # Contar a frequência de cada conjunto de coordenadas\n",
    "    contador = Counter(coords_lista)\n",
    "    # Selecionar a coordenada mais frequente\n",
    "    mais_frequente = contador.most_common(1)[0][0]\n",
    "    coordenadas_selecionadas_uma[palavra] = mais_frequente\n",
    "\n",
    "for hand_label in ['direita', 'esquerda']:\n",
    "    for palavra, coords_lista in coordenadas_por_palavra['duas'].items():\n",
    "        # Contar a frequência de cada conjunto de coordenadas\n",
    "        contador = Counter(coords_lista)\n",
    "        # Selecionar a coordenada mais frequente\n",
    "        mais_frequente = contador.most_common(1)[0][0]\n",
    "        coordenadas_selecionadas_duas[hand_label][palavra] = mais_frequente\n",
    "\n",
    "# Preparando os dados para treinamento\n",
    "dados_filtrados_uma = []\n",
    "rotulos_filtrados_uma = []\n",
    "dados_filtrados_duas = []\n",
    "rotulos_filtrados_duas = []\n",
    "\n",
    "for palavra, coords in coordenadas_selecionadas_uma.items():\n",
    "    dados_filtrados_uma.append(coords)\n",
    "    rotulos_filtrados_uma.append(palavra)\n",
    "\n",
    "for hand_label in ['direita', 'esquerda']:\n",
    "    for palavra, coords in coordenadas_selecionadas_duas[hand_label].items():\n",
    "        dados_filtrados_duas.append(coords)\n",
    "        rotulos_filtrados_duas.append(palavra)\n",
    "\n",
    "# Convertendo as listas em arrays numpy\n",
    "dados_uma_mao = np.array(dados_filtrados_uma)\n",
    "rotulos_uma_mao = np.array(rotulos_filtrados_uma)\n",
    "dados_duas_maos = np.array(dados_filtrados_duas)\n",
    "rotulos_duas_maos = np.array(rotulos_filtrados_duas)\n",
    "\n",
    "# Balanceamento dos dados\n",
    "min_amostras_uma = min(Counter(rotulos_uma_mao).values())\n",
    "dados_balanceados_uma = []\n",
    "rotulos_balanceados_uma = []\n",
    "for palavra in coordenadas_selecionadas_uma.keys():\n",
    "    indices = [i for i, r in enumerate(rotulos_uma_mao) if r == palavra]\n",
    "    indices_selecionados = np.random.choice(indices, min_amostras_uma, replace=False)\n",
    "    dados_balanceados_uma.extend(dados_uma_mao[indices_selecionados])\n",
    "    rotulos_balanceados_uma.extend(rotulos_uma_mao[indices_selecionados])\n",
    "\n",
    "dados_balanceados_uma = np.array(dados_balanceados_uma)\n",
    "rotulos_balanceados_uma = np.array(rotulos_balanceados_uma)\n",
    "\n",
    "min_amostras_duas = min(Counter(rotulos_duas_maos).values())\n",
    "dados_balanceados_duas = []\n",
    "rotulos_balanceados_duas = []\n",
    "for palavra in coordenadas_selecionadas_duas['direita'].keys():\n",
    "    indices = [i for i, r in enumerate(rotulos_duas_maos) if r == palavra]\n",
    "    indices_selecionados = np.random.choice(indices, min_amostras_duas, replace=False)\n",
    "    dados_balanceados_duas.extend(dados_duas_maos[indices_selecionados])\n",
    "    rotulos_balanceados_duas.extend(rotulos_duas_maos[indices_selecionados])\n",
    "\n",
    "dados_balanceados_duas = np.array(dados_balanceados_duas)\n",
    "rotulos_balanceados_duas = np.array(rotulos_balanceados_duas)\n",
    "\n",
    "# Dividindo os dados em conjuntos de treinamento e teste\n",
    "X_train_uma, X_test_uma, y_train_uma, y_test_uma = train_test_split(dados_balanceados_uma, rotulos_balanceados_uma, test_size=0.2, random_state=42)\n",
    "X_train_duas, X_test_duas, y_train_duas, y_test_duas = train_test_split(dados_balanceados_duas, rotulos_balanceados_duas, test_size=0.2, random_state=42)\n",
    "\n",
    "# Treinando os modelos com as coordenadas selecionadas\n",
    "modelo_uma = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "modelo_uma.fit(X_train_uma, y_train_uma)\n",
    "\n",
    "modelo_duas = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "modelo_duas.fit(X_train_duas, y_train_duas)\n",
    "\n",
    "# Avaliando os modelos\n",
    "score_uma = modelo_uma.score(X_test_uma, y_test_uma)\n",
    "score_duas = modelo_duas.score(X_test_duas, y_test_duas)\n",
    "print(f'Acurácia do modelo (uma mão): {score_uma*100:.2f}%')\n",
    "print(f'Acurácia do modelo (duas mãos): {score_duas*100:.2f}%')\n",
    "\n",
    "# Salvando os modelos\n",
    "joblib.dump(modelo_uma, 'modelo_uma_mao.pkl')\n",
    "joblib.dump(modelo_duas, 'modelo_duas_maos.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
